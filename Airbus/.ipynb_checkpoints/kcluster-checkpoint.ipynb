{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import os \n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = ''\n",
    "DATA_PATH = INPUT_PATH\n",
    "TRAIN_DATA = os.path.join(DATA_PATH, \"train\")\n",
    "TRAIN_MASKS_DATA = os.path.join(DATA_PATH, \"train/masks\")\n",
    "TEST_DATA = os.path.join(DATA_PATH, \"test\")\n",
    "df = pd.read_csv(DATA_PATH+'train_ship_segmentations_v2.csv')\n",
    "path_train = 'train/'\n",
    "path_test = 'test/'\n",
    "train_ids = df.ImageId.values\n",
    "df = df.set_index('ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_no_ship = df.index[df.EncodedPixels.isnull()==True]\n",
    "print ('Found ' + str(len(images_with_no_ship)) + ' no-ship images') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Number of distinct classes \n",
    "NUM_CLASSES = 50\n",
    "#\n",
    "# In order to reduce computation time, downsample train images. \n",
    "# Sure we loose some pixel information this way.....\n",
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_filename(image_id, image_type):\n",
    "    check_dir = False\n",
    "    if \"Train\" == image_type:\n",
    "        data_path = TRAIN_DATA\n",
    "    elif \"mask\" in image_type:\n",
    "        data_path = TRAIN_MASKS_DATA\n",
    "    elif \"Test\" in image_type:\n",
    "        data_path = TEST_DATA\n",
    "    else:\n",
    "        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n",
    "\n",
    "    if check_dir and not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    return os.path.join(data_path, \"{}\".format(image_id))\n",
    "\n",
    "\n",
    "def get_image_data_opencv(image_id, image_type, **kwargs):\n",
    "    fname = get_filename(image_id, image_type)\n",
    "    img = cv2.imread(fname)\n",
    "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    return img\n",
    "\n",
    "def get_domimant_colors(img, top_colors=2):\n",
    "    img_l = img.reshape((img.shape[0] * img.shape[1], img.shape[2]))\n",
    "    clt = KMeans(n_clusters = top_colors)\n",
    "    clt.fit(img_l)\n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
    "    # normalize the histogram, such that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    return clt.cluster_centers_, hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = []\n",
    "for imfile in tqdm(images_with_no_ship):\n",
    "    image_hsv = get_image_data_opencv(imfile, \"Train\")\n",
    "    height, width, l = image_hsv.shape\n",
    "    dominant_colors_hsv, dominant_rates_hsv = get_domimant_colors(image_hsv, top_colors=1)\n",
    "    dominant_colors_hsv = dominant_colors_hsv.reshape(1, dominant_colors_hsv.shape[0] * dominant_colors_hsv.shape[1])\n",
    "    info = (imfile, width, height, dominant_colors_hsv.squeeze())\n",
    "    details.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols  = ['image_id', 'image_width', 'image_height', 'hsv_dominant']\n",
    "trainPD = pd.DataFrame(details, columns=cols)\n",
    "X = (pd.DataFrame(trainPD['hsv_dominant'].values.tolist())).as_matrix()\n",
    "kmeans = KMeans(n_clusters=50).fit(X)\n",
    "clusters = kmeans.predict(X)\n",
    "trainPD['hsv_cluster'] = clusters\n",
    "trainPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = trainPD.groupby('hsv_cluster')['image_id'].count()\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('#images per partition')\n",
    "plt.bar(np.arange(50), hist.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, images_rows, images_cols):\n",
    "    f, axarr = plt.subplots(images_rows,images_cols,figsize=(16,images_rows*2))\n",
    "    for row in range(images_rows):\n",
    "        for col in range(images_cols):\n",
    "            image_id = images[row*images_cols + col]\n",
    "            image = cv2.imread(get_filename(image_id, 'Train'))\n",
    "            height, width, l = image.shape\n",
    "            ax = axarr[row,col]\n",
    "            ax.axis('off')\n",
    "            ax.set_title(\"%dx%d\"%(width, height))\n",
    "            ax.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(trainPD[trainPD['hsv_cluster'] == 0]['image_id'].values, 4, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(trainPD[trainPD['hsv_cluster'] == 1]['image_id'].values, 4, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(trainPD[trainPD['hsv_cluster'] == 30]['image_id'].values, 4, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPD.to_csv('noship_clusters.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
